# 02_LLM_INFERENCE_API: RAG Engine Microservice
This service hosts the LLM and encapsulates all complex RAG logic (Code-Aware Filtering, Multi-Layer Retrieval). Provides the single /generate_config API. Team 2 owns this entire stack.
